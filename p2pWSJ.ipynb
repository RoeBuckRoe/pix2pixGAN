{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p2pWSJ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIQ7lpFwm3j-"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC5JcMCXm-c1"
      },
      "source": [
        "**Uploading zipped image filess**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYJ51CnM4s4a"
      },
      "source": [
        "from google.colab import files\r\n",
        "\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT5bcOj9F0zf"
      },
      "source": [
        "!unzip -q 'pot2hed.zip' #unzip the uploaded files\r\n",
        "!ls #view the contents of the uploaded file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zLoGZHdncEE"
      },
      "source": [
        "Writting the image files to .NPZ file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKoh5NXMysyI"
      },
      "source": [
        "from os import listdir\r\n",
        "from numpy import asarray\r\n",
        "from numpy import vstack\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "from numpy import savez_compressed\r\n",
        " \r\n",
        "# load all images in a directory into memory\r\n",
        "def load_images(path, size=(256,256,3)):\r\n",
        "\timg_list = list()\r\n",
        "\t# enumerate filenames in directory (all are images).\r\n",
        "\tfor filename in listdir(path):\r\n",
        "\t\t# load and resize the image\r\n",
        "\t\tpixels = load_img(path + filename, target_size=size)\r\n",
        "\t\t# convert to numpy array\r\n",
        "\t\tpixels = img_to_array(pixels)\r\n",
        "\t\timg= pixels\r\n",
        "\t\timg_list.append(img)\r\n",
        "\treturn [asarray(img_list)]\r\n",
        " \r\n",
        "# dataset path\r\n",
        "path = '/content/potr2hedc/potr/'\r\n",
        "# load dataset\r\n",
        "[src_images] = load_images(path)\r\n",
        "print('Loaded: ', src_images.shape)\r\n",
        "# save as compressed numpy array\r\n",
        "path = '/content/potr2hedc/hedc/'\r\n",
        "# load dataset\r\n",
        "[tar_images] = load_images(path)\r\n",
        "print('Loaded: ', tar_images.shape)\r\n",
        "filename = 'potr2hedc_256.npz'\r\n",
        "savez_compressed(filename, src_images, tar_images)\r\n",
        "print('Saved dataset: ', filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIKKKTTznq9f"
      },
      "source": [
        "# Pip2pix Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BzCLDawYb36"
      },
      "source": [
        "from numpy import load\r\n",
        "from numpy import zeros\r\n",
        "from numpy import ones\r\n",
        "from numpy.random import randint\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.initializers import RandomNormal\r\n",
        "from keras.models import Model\r\n",
        "from keras.models import Input\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import Conv2DTranspose\r\n",
        "from keras.layers import LeakyReLU\r\n",
        "from keras.layers import Activation\r\n",
        "from keras.layers import Concatenate\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers import BatchNormalization\r\n",
        "from keras.layers import LeakyReLU\r\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dAdanhpn8qt"
      },
      "source": [
        "**Discrimonator model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk7VIsc1YkNw"
      },
      "source": [
        "def discriminator(image_shape):\r\n",
        "  # weight initialization\r\n",
        "  init = RandomNormal(stddev=0.02)\r\n",
        "  # potrait image input\r\n",
        "  in_potr_image = Input(shape=image_shape)\r\n",
        "  # Hedcut image input\r\n",
        "  in_hedc_image = Input(shape=image_shape)\r\n",
        "  # concatenate images channel-wise\r\n",
        "  merged = Concatenate()([in_potr_image, in_hedc_image])\r\n",
        "  # Conv64\r\n",
        "  d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\r\n",
        "  d = LeakyReLU(alpha=0.2)(d)\r\n",
        "  # Conv128\r\n",
        "  d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\r\n",
        "  d = BatchNormalization()(d)\r\n",
        "  d = LeakyReLU(alpha=0.2)(d)\r\n",
        "  # Conv256\r\n",
        "  d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\r\n",
        "  d = BatchNormalization()(d)\r\n",
        "  d = LeakyReLU(alpha=0.2)(d)\r\n",
        "  # Conv512\r\n",
        "  d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\r\n",
        "  d = BatchNormalization()(d)\r\n",
        "  d = LeakyReLU(alpha=0.2)(d)\r\n",
        "  # second last output layer\r\n",
        "  d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\r\n",
        "  d = BatchNormalization()(d)\r\n",
        "  d = LeakyReLU(alpha=0.2)(d)\r\n",
        "  # patch output\r\n",
        "  d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\r\n",
        "  patch_out = Activation('sigmoid')(d)\r\n",
        "  # define model\r\n",
        "  model = Model([in_potr_image, in_hedc_image], patch_out)\r\n",
        "  # compile model\r\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\r\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4xFUHKPq-zq"
      },
      "source": [
        "Encoder block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPOd_SmOYw0I"
      },
      "source": [
        "def enc_block(layer_in, n_filters, batchnorm=True):\r\n",
        "  # weight initialization\r\n",
        "  init = RandomNormal(stddev=0.02)\r\n",
        "  # add downsampling layer\r\n",
        "  g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same',\r\n",
        "  kernel_initializer=init)(layer_in)\r\n",
        "  # conditionally add batch normalization\r\n",
        "  if batchnorm:\r\n",
        "    g = BatchNormalization()(g, training=True)\r\n",
        "  # leaky relu activation\r\n",
        "  g = LeakyReLU(alpha=0.2)(g)\r\n",
        "  return g\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBZ3z-_RrByx"
      },
      "source": [
        "Decoder Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmO3z_g-Y6vf"
      },
      "source": [
        "def dec_block(layer_in, skip_in, n_filters, dropout=True):\r\n",
        "  # weight initialization\r\n",
        "  init = RandomNormal(stddev=0.02)\r\n",
        "  # add upsampling layer\r\n",
        "  g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same',\r\n",
        "  kernel_initializer=init)(layer_in)\r\n",
        "  # add batch normalization\r\n",
        "  g = BatchNormalization()(g, training=True)\r\n",
        "  # conditionally add dropout\r\n",
        "  if dropout:\r\n",
        "    g = Dropout(0.5)(g, training=True)\r\n",
        "  # merge with skip connection\r\n",
        "  g = Concatenate()([g, skip_in])\r\n",
        "  # relu activation\r\n",
        "  g = Activation('relu')(g)\r\n",
        "  return g\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI8fvW5dq5cM"
      },
      "source": [
        "**Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl3TLU5aZavo"
      },
      "source": [
        "def generator(image_shape=(256,256,3)):\r\n",
        "  # weight initialization\r\n",
        "  init = RandomNormal(stddev=0.02)\r\n",
        "  # image input\r\n",
        "  in_image = Input(shape=image_shape)\r\n",
        "  # encoder model\r\n",
        "  e1 = enc_block(in_image, 64, batchnorm=False)\r\n",
        "  e2 = enc_block(e1, 128)\r\n",
        "  e3 = enc_block(e2, 256)\r\n",
        "  e4 = enc_block(e3, 512)\r\n",
        "  e5 = enc_block(e4, 512)\r\n",
        "  e6 = enc_block(e5, 512)\r\n",
        "  e7 = enc_block(e6, 512)\r\n",
        "  # bottleneck, no batch norm and relu\r\n",
        "  b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\r\n",
        "  b = Activation('relu')(b)\r\n",
        "  # decoder model\r\n",
        "  d1 = dec_block(b, e7, 512)\r\n",
        "  d2 = dec_block(d1, e6, 512)\r\n",
        "  d3 = dec_block(d2, e5, 512)\r\n",
        "  d4 = dec_block(d3, e4, 512, dropout=False)\r\n",
        "  d5 = dec_block(d4, e3, 256, dropout=False)\r\n",
        "  d6 = dec_block(d5, e2, 128, dropout=False)\r\n",
        "  d7 = dec_block(d6, e1, 64, dropout=False)\r\n",
        "  # output\r\n",
        "  g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\r\n",
        "  out_image = Activation('tanh')(g)\r\n",
        "  # define model\r\n",
        "  model = Model(in_image, out_image)\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLDdHoSlrHMg"
      },
      "source": [
        "GAN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJkIMCh7Zn-5"
      },
      "source": [
        "def pix2pix_gan(g_model, d_model, image_shape):\r\n",
        "  # make weights in the discriminator not trainable\r\n",
        "  d_model.trainable = False\r\n",
        "  # define the source image\r\n",
        "  in_potr = Input(shape=image_shape)\r\n",
        "  # connect the source image to the generator input\r\n",
        "  gen_out = g_model(in_potr)\r\n",
        "  # connect the source input and generator output to the discriminator input\r\n",
        "  dis_out = d_model([in_potr, gen_out])\r\n",
        "  # src image as input, generated image and classification output\r\n",
        "  model = Model(in_potr, [dis_out, gen_out])\r\n",
        "  # compile model\r\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\r\n",
        "  model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\r\n",
        "  return model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW9KxHx4rLPQ"
      },
      "source": [
        "**Loading data **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZAf7QfEZxLA"
      },
      "source": [
        "def load_real_samples(filename):\r\n",
        "  # load the compressed arrays\r\n",
        "  data = load(filename)\r\n",
        "  # unpack the arrays\r\n",
        "  X1, X2 = data['arr_0'], data['arr_1']\r\n",
        "  # scale from [0,255] to [-1,1]\r\n",
        "  X1 = (X1 - 127.5) / 127.5\r\n",
        "  X2 = (X2 - 127.5) / 127.5\r\n",
        "  return [X1, X2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF7vr02LrWlm"
      },
      "source": [
        "Real sample generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv8u9g2JZ6r_"
      },
      "source": [
        "def generate_real_samples(dataset, n_samples, patch_shape):\r\n",
        "  # unpack dataset\r\n",
        "  trainA, trainB = dataset\r\n",
        "  # choose random instances\r\n",
        "  ix = randint(0, trainA.shape[0], n_samples)\r\n",
        "  # retrieve selected images\r\n",
        "  X1, X2 = trainA[ix], trainB[ix]\r\n",
        "  # generate 'real' class labels (1)\r\n",
        "  y = ones((n_samples, patch_shape, patch_shape, 1))\r\n",
        "  return [X1, X2], y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEDWYRDEtAwI"
      },
      "source": [
        "Fake sample generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITfFP3-PZ-yC"
      },
      "source": [
        "def generate_fake_samples(g_model, samples, patch_shape):\r\n",
        "  # generate fake instance\r\n",
        "  X = g_model.predict(samples)\r\n",
        "  # create 'fake' class labels (0)\r\n",
        "  y = zeros((len(X), patch_shape, patch_shape, 1))\r\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcIu6bdktPJ3"
      },
      "source": [
        "**Model performanc**e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ga9GAtSaCHH"
      },
      "source": [
        "def summarize_performance(step, g_model, dataset, n_samples=3):\r\n",
        "  # select a sample of input images\r\n",
        "  [X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\r\n",
        "  # generate a batch of fake samples\r\n",
        "  X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\r\n",
        "  # scale all pixels from [-1,1] to [0,1]\r\n",
        "  X_realA = (X_realA + 1) / 2.0\r\n",
        "  X_realB = (X_realB + 1) / 2.0\r\n",
        "  X_fakeB = (X_fakeB + 1) / 2.0\r\n",
        "  # plot real source images\r\n",
        "  for i in range(n_samples):\r\n",
        "    pyplot.subplot(3, n_samples, 1 + i)\r\n",
        "    pyplot.axis('off')\r\n",
        "    pyplot.imshow(X_realA[i])\r\n",
        "    # plot generated target image\r\n",
        "  for i in range(n_samples):\r\n",
        "    pyplot.subplot(3, n_samples, 1 + n_samples + i)\r\n",
        "    pyplot.axis('off')\r\n",
        "    pyplot.imshow(X_fakeB[i])\r\n",
        "    # plot real target image\r\n",
        "  for i in range(n_samples):\r\n",
        "    pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\r\n",
        "    pyplot.axis('off')\r\n",
        "    pyplot.imshow(X_realB[i])\r\n",
        "  # save plot to file\r\n",
        "  filename1 = 'plot_%06d.png' % (step+1)\r\n",
        "  pyplot.savefig(filename1)\r\n",
        "  pyplot.close()\r\n",
        "  # save the generator model\r\n",
        "  filename2 = 'model_%06d.h5' % (step+1)\r\n",
        "  g_model.save(filename2)\r\n",
        "  print('>Saved: %s and %s' % (filename1, filename2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4Ir6gRNtExg"
      },
      "source": [
        "**Model trainer**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyOjfb2facaQ"
      },
      "source": [
        "def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\r\n",
        "  # determine the output square shape of the discriminator\r\n",
        "  n_patch = d_model.output_shape[1]\r\n",
        "  # unpack dataset\r\n",
        "  trainA, trainB = dataset\r\n",
        "  # calculate the number of batches per training epoch\r\n",
        "  bat_per_epo = int(len(trainA) / n_batch)\r\n",
        "  # calculate the number of training iterations\r\n",
        "  n_steps = bat_per_epo * n_epochs\r\n",
        "  # manually enumerate epochs\r\n",
        "  for i in range(n_steps):\r\n",
        "    # select a batch of real samples\r\n",
        "    [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\r\n",
        "    # generate a batch of fake samples\r\n",
        "    X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\r\n",
        "    # update discriminator for real samples\r\n",
        "    d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\r\n",
        "    # update discriminator for generated samples\r\n",
        "    d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\r\n",
        "    # update the generator\r\n",
        "    g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\r\n",
        "    # summarize performance\r\n",
        "    print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\r\n",
        "    # summarize model performance\r\n",
        "    if (i+1) % (bat_per_epo * 10) == 0:\r\n",
        "      summarize_performance(i, g_model, dataset)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KycCcGp1tIJ3"
      },
      "source": [
        "**Main function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eMD4e-gar0k"
      },
      "source": [
        "dataset = load_real_samples('potr2hedc_256.npz')\r\n",
        "print('Loaded', dataset[0].shape, dataset[1].shape)\r\n",
        "# define input shape based on the loaded dataset\r\n",
        "image_shape = dataset[0].shape[1:]\r\n",
        "# define the models\r\n",
        "d_model = discriminator(image_shape)\r\n",
        "g_model = generator(image_shape)\r\n",
        "# define the composite model\r\n",
        "gan_model = pix2pix_gan(g_model, d_model, image_shape)\r\n",
        "# train model\r\n",
        "train(d_model, g_model, gan_model, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}